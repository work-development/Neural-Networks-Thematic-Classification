{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f283f762",
   "metadata": {},
   "source": [
    "### Словарь и вектор весов     \n",
    "\n",
    "Дана коллекция текстов. Построим словарь (отображение из строкового представления токенов в их номера) и вектор весов (DF).    \n",
    "\n",
    "$DF(w)=\\frac{DocCount(w,c)}{size(c)}$   -- частота слова w в коллекции c (отношение количества документов, в которых слово используется, к общему количеству документов).     \n",
    "\n",
    "При токенизации используется регулярное выражение: [\\w\\d]+. После токенизации все токены приводятся к нижнему регистру. Фильтрация по частоте не используется.   \n",
    "\n",
    "В итоге получим:    \n",
    "\n",
    "- словарь - список уникальных токенов через пробел в порядке возрастания частоты встречаемости. При одинаковой частоте происходит сортировка по алфавиту.   \n",
    "- список весов (DF) токенов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8567d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "from dlnlputils.data import build_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45a46ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_RE = re.compile(r'[\\w\\d]+')\n",
    "def tokenize_text_simple_regex(txt, min_token_size=1):\n",
    "    txt = txt.lower()\n",
    "    all_tokens = TOKEN_RE.findall(txt)\n",
    "    return [token for token in all_tokens if len(token) >= min_token_size]\n",
    "\n",
    "def tokenize_corpus(texts, tokenizer=tokenize_text_simple_regex, **tokenizer_kwargs):\n",
    "    return [tokenizer(text, **tokenizer_kwargs) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f76f848c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нельзя не помиловать\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Казнить нельзя, помиловать. Нельзя наказывать.\", \"Казнить, нельзя помиловать. Нельзя освободить.\", \"Нельзя не помиловать.\", \"Обязательно освободить.\"]\n",
    "texts_tokenized = tokenize_corpus(texts)\n",
    "print(' '.join(texts_tokenized[2]))\n",
    "MAX_DF = 1\n",
    "MIN_COUNT = 0\n",
    "vocab, w_doc_freq = build_vocabulary(texts_tokenized, max_doc_freq=MAX_DF, min_count=MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943101ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75, 0.75, 0.5 , 0.5 , 0.25, 0.25, 0.25], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_doc_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "391c10de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'нельзя': 0,\n",
       " 'помиловать': 1,\n",
       " 'казнить': 2,\n",
       " 'освободить': 3,\n",
       " 'наказывать': 4,\n",
       " 'не': 5,\n",
       " 'обязательно': 6}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3e8490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'нельзя': 0.75,\n",
       " 'помиловать': 0.75,\n",
       " 'казнить': 0.5,\n",
       " 'освободить': 0.5,\n",
       " 'наказывать': 0.25,\n",
       " 'не': 0.25,\n",
       " 'обязательно': 0.25}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = {x[0]: w_doc_freq[x[1]] for x in vocab.items()}\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32aeeb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('наказывать', 0.25), ('не', 0.25), ('обязательно', 0.25), ('казнить', 0.5), ('освободить', 0.5), ('нельзя', 0.75), ('помиловать', 0.75)]\n"
     ]
    }
   ],
   "source": [
    "e = sorted(dd.items(), key=lambda pair: (pair[1],pair[0]))\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c41043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
